<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Face Registration & Recognition (Debug Version)</title>

  <!-- Load face-api.js (browser build) from a specific CDN version -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 20px;
    }
    #video, #overlay {
      position: relative;
      width: 640px;
      height: 480px;
      border: 1px solid #ccc;
      margin-top: 10px;
    }
    #controls {
      margin-bottom: 10px;
    }
    #status {
      margin-top: 10px;
      font-weight: bold;
      color: green;
    }
  </style>
</head>
<body>
  <h1>Face Registration & Recognition (Debug Version)</h1>

  <div id="controls">
    <label>
      Enter Name:
      <input type="text" id="nameInput" placeholder="e.g. Alice" />
    </label>
    <button id="registerBtn">Register Face</button>
    <button id="createMatcherBtn">Create Matcher</button>
    <button id="startRecBtn">Start Recognition</button>
  </div>

  <div id="status">Loading face-api.js models, please wait...</div>
  
  <!-- Webcam Video -->
  <video id="video" autoplay muted></video>
  <!-- Canvas Overlay for Drawing Boxes/Labels -->
  <canvas id="overlay"></canvas>

  <script>
    // -------------------------------------------------
    // GLOBALS / STATE
    // -------------------------------------------------
    let descriptorsByLabel = {};  // { label: [Float32Array, Float32Array, ...], ... }
    let faceMatcher = null;
    let videoStream = null;
    let recognitionActive = false; // we'll use this to toggle the detection loop

    // -------------------------------------------------
    // 1. LOAD MODELS & START WEBCAM
    // -------------------------------------------------
    window.addEventListener('DOMContentLoaded', async () => {
      console.log("[DEBUG] DOMContentLoaded - Start loading models...");
      const statusEl = document.getElementById('status');

      // Load the face-api.js models
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri('./models'),
          faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
          faceapi.nets.faceRecognitionNet.loadFromUri('./models')
        ]);
        statusEl.textContent = 'Models loaded! Initializing webcam...';
        console.log("[DEBUG] Models loaded successfully.");
      } catch (err) {
        statusEl.textContent = 'Error loading models: ' + err;
        console.error("[DEBUG] Model loading error:", err);
        return;
      }

      // Access user webcam
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
        const video = document.getElementById('video');
        video.srcObject = videoStream;
        video.onloadedmetadata = () => {
          video.play();
          statusEl.textContent = 'Webcam initialized. Ready to register faces.';
          console.log("[DEBUG] Webcam initialized.");
        };
      } catch (err) {
        statusEl.textContent = 'Error accessing webcam: ' + err;
        console.error("[DEBUG] Webcam error:", err);
      }
    });

    // -------------------------------------------------
    // 2. REGISTER A FACE (Capture a Descriptor)
    // -------------------------------------------------
    document.getElementById('registerBtn').addEventListener('click', async () => {
      console.log("[DEBUG] 'Register Face' clicked.");
      const name = document.getElementById('nameInput').value.trim();
      const statusEl = document.getElementById('status');

      if (!name) {
        alert('Please enter a name before registering.');
        return;
      }
      const video = document.getElementById('video');

      // Detect a single face in the current video frame
      const detection = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) {
        statusEl.textContent = 'No face detected. Please position your face clearly.';
        console.log("[DEBUG] No face detected for registration.");
        return;
      }

      // We have a 128-d embedding vector for the face
      const descriptor = detection.descriptor; // Float32Array(128)

      // Store descriptor under this label
      if (!descriptorsByLabel[name]) {
        descriptorsByLabel[name] = [];
      }
      descriptorsByLabel[name].push(descriptor);

      statusEl.textContent = `Face registered for "${name}". Samples for ${name}: ${descriptorsByLabel[name].length}`;
      console.log(`[DEBUG] Registered face for ${name}. Now have ${descriptorsByLabel[name].length} samples.`);
    });

    // -------------------------------------------------
    // 3. CREATE FACE MATCHER
    // -------------------------------------------------
    document.getElementById('createMatcherBtn').addEventListener('click', () => {
      console.log("[DEBUG] 'Create Matcher' clicked.");
      const statusEl = document.getElementById('status');
      const labeledFaceDescriptors = [];

      // Convert descriptorsByLabel to LabeledFaceDescriptors
      for (const label in descriptorsByLabel) {
        labeledFaceDescriptors.push(
          new faceapi.LabeledFaceDescriptors(label, descriptorsByLabel[label])
        );
        console.log(`[DEBUG] Label: ${label}, # of descriptors: ${descriptorsByLabel[label].length}`);
      }

      // Initialize a FaceMatcher with threshold=0.6 (tweak if needed)
      faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.6);
      statusEl.textContent = 'Face Matcher created! You can now start recognition.';
      console.log("[DEBUG] FaceMatcher created with threshold=0.6:", faceMatcher);
    });

    // -------------------------------------------------
    // 4. START RECOGNITION (REAL-TIME LOOP)
    // -------------------------------------------------
    document.getElementById('startRecBtn').addEventListener('click', () => {
      console.log("[DEBUG] 'Start Recognition' clicked.");
      const statusEl = document.getElementById('status');

      if (!faceMatcher) {
        alert('No matcher found! Please create the matcher first.');
        return;
      }

      if (recognitionActive) {
        console.log("[DEBUG] Recognition already active. Doing nothing.");
        return;
      }

      // We set a flag so we don't stack multiple loops
      recognitionActive = true;
      statusEl.textContent = 'Recognition started. Looking for registered faces...';

      // Kick off the detection loop
      recognizeFaces();
    });

    // The main detection loop using requestAnimationFrame
    async function recognizeFaces() {
      // If user stops or no longer wants recognition, we can do:
      // if (!recognitionActive) return;

      console.log("[DEBUG] recognizeFaces() called.");

      // Schedule next iteration
      requestAnimationFrame(recognizeFaces);

      const video = document.getElementById('video');
      const canvas = document.getElementById('overlay');
      const ctx = canvas.getContext('2d');

      // Match the canvas to the video size
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      // Detect all faces in current video frame
      const detections = await faceapi.detectAllFaces(
        video,
        new faceapi.TinyFaceDetectorOptions()
      ).withFaceLandmarks().withFaceDescriptors();

      console.log("[DEBUG] # of detections this frame:", detections.length);

      // Clear previous drawings
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // For each detected face, find best match
      detections.forEach(detection => {
        const box = detection.detection.box;
        const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
        console.log("[DEBUG] Best match:", bestMatch.toString());

        // Draw bounding box
        ctx.strokeStyle = '#00FF00';
        ctx.lineWidth = 2;
        ctx.strokeRect(box.x, box.y, box.width, box.height);

        // Draw label (bestMatch.toString() includes distance)
        ctx.fillStyle = '#00FF00';
        ctx.font = '16px Arial';
        ctx.fillText(bestMatch.toString(), box.x, box.y - 5);
      });
    }
  </script>
</body>
</html>
