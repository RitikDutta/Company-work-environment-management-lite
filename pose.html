<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Live Pose Prediction</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.5/drawing_utils.js"></script>

  <style>
    #output_canvas { border: 1px solid black; }
    #prediction { font-size: 24px; font-weight: bold; margin-top: 10px; }
  </style>
</head>

<body>
  <h1>Live Pose Prediction</h1>
  <video id="videoElement" width="640" height="480" autoplay muted style="display:none;"></video>
  <canvas id="output_canvas" width="640" height="480"></canvas>
  <div id="prediction">Prediction: None</div>

  <script>
    // Model setup
    let model;
    const modelURL = 'tfjs_model/model.json';

    // Elements
    const videoElement = document.getElementById('videoElement');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const predictionDiv = document.getElementById('prediction');

    // Load our model
    async function loadModel() {
      console.log("[DEBUG] Loading model from", modelURL);
      try {
        model = await tf.loadGraphModel(modelURL);
        console.log("[DEBUG] Model loaded successfully.");
      } catch (error) {
        console.error("[ERROR] Failed to load model:", error);
      }
    }

    // Initialize MediaPipe Pose
    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false,
      smoothSegmentation: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    pose.onResults(onPoseResults);

    // Process our pose results
    async function onPoseResults(results) {
      console.log("[DEBUG] Received pose results.");
      
      // Draw video frame
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      // If no landmarks, reset and exit
      if (!results.poseLandmarks) {
        console.log("[DEBUG] No pose detected.");
        predictionDiv.innerText = "Prediction: No pose detected";
        canvasCtx.restore();
        return;
      }

      // Draw landmarks
      window.drawConnectors(canvasCtx, results.poseLandmarks, window.POSE_CONNECTIONS,
                            { color: '#00FF00', lineWidth: 4 });
      window.drawLandmarks(canvasCtx, results.poseLandmarks,
                           { color: '#FF0000', lineWidth: 2 });
      canvasCtx.restore();

      // Prepare input for our model
      let inputArray = [];
      results.poseLandmarks.forEach(lm => {
        inputArray.push(lm.x, lm.y, lm.z, lm.visibility);
      });

      console.log("[DEBUG] Input tensor shape:", inputArray.length);

      const inputTensor = tf.tensor(inputArray, [1, inputArray.length]);
      
      // Run our prediction
      try {
        const predictionTensor = await model.predict(inputTensor);
        const predictionData = await predictionTensor.data();
        console.log("[DEBUG] Prediction data:", predictionData);

        // Get highest probability class
        const maxIndex = predictionData.indexOf(Math.max(...predictionData));
        console.log("[DEBUG] Predicted index:", maxIndex);

        // Map to our class labels
        const classLabels = ['looking_away', 'phone', 'working'];
        const predictedClass = classLabels[maxIndex] || "Unknown";
        console.log("[DEBUG] Predicted class:", predictedClass);

        // Display prediction
        predictionDiv.innerText = "Prediction: " + predictedClass;

        // Free memory
        inputTensor.dispose();
        predictionTensor.dispose();
      } catch (error) {
        console.error("[ERROR] Prediction failed:", error);
      }
    }

    // Start webcam with MediaPipe
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await pose.send({ image: videoElement });
      },
      width: 640,
      height: 480
    });

    // Start our app
    async function startApp() {
      console.log("[DEBUG] Starting app...");
      await loadModel();
      console.log("[DEBUG] Starting camera...");
      camera.start();
    }

    startApp();
  </script>
</body>
</html>
